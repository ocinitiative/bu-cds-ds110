# -*- coding: utf-8 -*-
"""DS 110 Final Project Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XQ0KaNEFgl9H4nILf5IYM32M3A9CWnhK

# DS 110 Final Project Code

# Pre-ML

## Preparation
"""

# Importing the libraries

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import re
import random

"""For next step, you will need to use the file flavors_of_cacao.csv.

If you don't have it locally, feel free to download it on [GitHub](https://github.com/SuzzukiW/chocolate-ratings-prediction-ml-model/blob/main/Datasets/flavors_of_cacao.csv).


"""

# Importing the dataset

from google.colab import files

uploaded = files.upload()

# Loading data

df = pd.read_csv("flavors_of_cacao.csv")

"""## Overview of the dataset"""

# Have a look on the unprocessed data

df.head()

df.dtypes

# A function for data overview

def basic_info(df):
    
    # Shape of the dataframe
    print("Number of Instances:",df.shape[0])
    print("Number of Features:",df.shape[1])
    
    # Summary Stats
    print("\nSummary Stats:")
    print(df.describe())
    
    # Missing Value
    print("\nMissing Values:")
    print(df.isna().sum())

    # Info for columns
    print("\nInfo for Columns:")
    print(df.columns)

basic_info(df)

"""# Data Cleansing

## Renaming columns
"""

# Checking name of the columns before renaming

df.columns

# Renaming the columns

df.columns = ["Company", "Specific_Origin", "REF", "Review_Date", "Cocoa_Percent", "Location", "Rating", "Bean_Type", "Broad_Origin"]

df.head()

# Have a look at it after the renaming

df.sample()

"""## Feature Engineering

### Rating

In this step, we will convert string to float for "Cocoa Percent" because Python won't be able to identify the special character like "%".

The percent sign (%) will be replaced with float number in Cocoa Percent.
"""

# Rewrite a function for converting Rating from string to float

# For exmaple, from '68%' to '68'

def removePercents(data):
    return data.apply(lambda x: float(x.strip('%')) / 100)

df['Cocoa_Percent'] = removePercents(df['Cocoa_Percent'])

df.sample()

"""### Company"""

df["Company"] = df.Company.apply(lambda x: re.split("\(|aka ",x.rstrip(")"))[-1])

"""Only keep the ones with more than 20 observations - set the others to "other'"
"""

company = df[["Company","REF"]].groupby("Company").count().reset_index() # sort_values(by = "REF", ascending = False).reset_index()
company["New_Company"] = company.apply(lambda x: x.Company if x.REF > 20 else "Other", axis=1)
company

df = df.merge(company[["Company","New_Company"]], how = "left", on = "Company")

"""### Bean Type

Base on observations, the largest group has no category name, and encoded as '\xa0', then there are the Trinitario, Criollo, and Forastero cocoa beans.

Also, there is the blend category, plus several categories that specify two types of beans, plus some that appear to be identifying a sub-type.

To simplify this, we will create a new Bean Type feature (called New_Bean_Type) as follows:
- Convert NaNs and other empty strings to "Not specified"
- Convert categories with two bean types to "Blend". As there are quite a few Criollo blends (in particular Criollo/Trinitario) keep these separate from the other blends in case this is significant.
- Remove any sub-type.
"""

# Renoving subtype "Blend"

df['New_Bean_Type'] = df.Bean_Type.replace(np.nan, 'not-specified', regex=True).replace('\xa0', 'not-specified').apply(
    lambda x : ("Blend-Criollo" if "Criollo" in re.split(" |,|\)",str(x)) else "Blend") if any(
        word in x for word in ['Blend',',']) else x).apply(lambda x : (x.split()[0]))

df.describe(exclude=[np.number])

# See what bean types we have now after this process

df.groupby('New_Bean_Type').New_Bean_Type.count()

df.sample()

"""### Broad Origin and Specific Origin

Combining and fixing data in Broad Origin
"""

#

df["New_Origin"] = df.Broad_Origin.replace(np.nan, 'NA', regex=True).replace(
    '\xa0', 'NA').str.replace('Dom.*','Dominican Republic').str.replace('Ven.*','Venezuela').apply(
    lambda x: re.split(',|\(|\/|\&|\-',str(x))[0].rstrip().replace('Cost ','Costa ').replace('DR','Dominican Republic').replace(
        'Tobago','Trinidad').replace('Trinidad','Trinidad and Tobago').replace("Carribean","Caribbean"))

# Sorting alphabetically

print(df.groupby('New_Origin').New_Origin.count().sort_index())

# 

df["New_Origin"] = df.New_Origin.apply(
    lambda x: x.replace('Gre.','Grenada').replace('Guat.','Guatemala').replace("Hawaii","United States of America").replace(
        'Mad.','Madagascar').replace('PNG','Papua New Guinea').replace('Principe','Sao Tome').replace(
        'Sao Tome','Sao Tome and Principe'))

print(df.groupby('New_Origin').New_Origin.count().sort_index())

"""For next step, you will need to the download the file 'countryContinent.csv' to import the dataset.

[Link to GitHub](https://github.com/SuzzukiW/chocolate-ratings-prediction-ml-model/blob/main/Datasets/countryContinent.csv)
"""

# Import Country to Continent dataset

from google.colab import files

uploaded = files.upload()

# Load Country to Continent dataset

ctoc_raw = pd.read_csv("countryContinent.csv", encoding='iso-8859-1') # format encoding for access

# Accessing unique countries


countries = ctoc_raw[["country","sub_region","continent"]]
countries.country = countries.country.apply(lambda x: re.split("\(|\,",x)[0].rstrip())
countries = countries.drop_duplicates()
countries

# Standard formatting

df["New_Origin"] = df["New_Origin"] = df.New_Origin.apply(
    lambda x: x.replace("St.","Saint").replace("Viet Nam","Vietnam").replace("Burma","Myanmar").replace(
        "Ivory Coast","CÃ´te d'Ivoire").replace("West","Western").replace(" and S. "," "))
print(df.groupby('New_Origin').New_Origin.count().sort_index())

# Merge the chocolate and countries dataframes to set a sub_region for each country (final merging)

df = df.merge(countries[["country","sub_region"]], how = "left", left_on= "New_Origin", right_on="country")
df[df.country.isnull()].groupby("New_Origin").New_Origin.count().sort_index()

# Fix data for Hawaii (state > country)

df.loc[df.New_Origin == "Hawaii","country"] = "United States of America"
df.loc[df.New_Origin == "Hawaii","sub_region"] = "Northern America"

df.loc[df.country.isnull(),"sub_region"] = df.loc[df.country.isnull(),"New_Origin"]
df.loc[df.country.isnull(),"country"] = "--"

# Fix data for Africa

regions = countries[["sub_region","continent"]].drop_duplicates()
df = df.merge(regions, how="left", on="sub_region")
df.loc[df.New_Origin=='Africa',"continent"] = 'Africa'
df.continent = df.continent.replace(np.nan,"other")

print(df[["continent","sub_region","country","New_Origin"]].groupby(["continent","sub_region","country"]).count())

# Setting all the small country categories to the sub_region

dfCounts = df[["New_Origin","REF"]].groupby(["New_Origin"]).count()
dfCounts.columns = ["countryCount"]
dfRollup = df.merge(dfCounts, how="left", left_on="New_Origin", right_index=True)[["New_Origin","sub_region","countryCount"]]
df.Origin = dfRollup.apply(lambda x: x.sub_region if x.countryCount < 28 else x.New_Origin, axis=1)

# 
print(df[["continent","sub_region","country","New_Origin"]].groupby(["continent","sub_region","New_Origin"]).count())

# Repeat this process

dfCounts = df[["New_Origin","REF"]].groupby(["New_Origin"]).count()
dfCounts.columns = ["countryCount"]
dfRollup = df.merge(dfCounts, how="left", left_on="New_Origin", right_index=True)[["New_Origin","continent","countryCount"]]
df.New_Origin = dfRollup.apply(lambda x: x.continent if x.countryCount < 28 else x.New_Origin, axis=1)


print(df[["continent","country","New_Origin"]].groupby(["continent","New_Origin"]).count())

print(df[["continent","sub_region","country","New_Origin"]].groupby(["continent","sub_region","New_Origin"]).count())

#

print(df.loc[df.Origin.str.contains("America"),["New_Origin","Broad_Origin","country"]].groupby(["New_Origin","Broad_Origin"]).count())

# 

df.loc[df.New_Origin.isin(["Americas","Central America"]),"New_Origin"] = "Central and South America"
print(df[["continent","country","New_Origin"]].groupby(["continent","New_Origin"]).count())

"""### Revamp the dataframe"""

df = df.loc[:,["Rating", "Cocoa_Percent", "New_Company", "New_Bean_Type", "New_Origin"]]
df.columns = ["Rating","Cocoa_Percent","Company","Bean_Type", "New_Origin"]
df.dtypes

df.head()

df.sample()

"""# Data Splitting & Get Dummies

## Traning & Testing Data
"""

# Randomly select 20% of the data and set aside as the test data

random.seed(12345) # 
# The purpose of this line of code is to make the random number predictable

testSize = len(df) // 5 # Set the testIndices to a random sample of the length of the dataframe
testIndices = random.sample(range(len(df)),testSize) # A list of random indices
testIndices.sort() # Sort the testIndices

# Set the test dataframe to the rows with the indices in testIndices

dfTest = df.iloc[testIndices,]

# Display

print("Test data set has {} observations and {} attributes".format(dfTest.shape[0],dfTest.shape[1]))

# Then, the rest of the data will be sed to train the model

dfTrain = df.drop(testIndices)

# Display

print("Training data set has {} observations and {} attributes".format(dfTrain.shape[0],dfTrain.shape[1]))

"""## Get Dummies

As model expect all the attributes to be numeric, therefore in this section, we will convert the categorical features to dummy variables.
"""

# Get dummies for the training data
X_train = pd.get_dummies(dfTrain.iloc[:,1:])

# Get the target variable (Rating) from the training data
y_train = dfTrain.Rating

print("Training data set has {} observations and {} attributes".format(X_train.shape[0],X_train.shape[1]))

# Get dummies for the testing data
X_test = pd.get_dummies(dfTest.iloc[:,1:])

# Get the target variable (Rating) from the testing data
y_test = dfTest.Rating

print("Test data set has {} observations and {} attributes".format(X_test.shape[0],X_test.shape[1]))

"""# Decision Tree Regression


"""

# Import the libraries

from sklearn.tree import DecisionTreeRegressor
from sklearn import tree
from sklearn.tree import _tree

# Create the Decision Tree Regressor

dtm = tree.DecisionTreeRegressor(max_depth = 5)
dtm.fit(X_train,y_train)

# This is a function to representing the decision tree model as a function
# tree: decision tree model: the decision tree to represent as a function
# feature_names: list: The feature names of the dataset used for building the decision tree

# Citation: Matthew Mayo, KDnuggets


def dtmToCode(tree, feature_names):

    tree_ = tree.tree_
    feature_name = [
        feature_names[i] if i != _tree.TREE_UNDEFINED else "undefined!"
        for i in tree_.feature
    ]
    
    print("def tree({}):".format(", ".join(feature_names)))

    
    def recurse(node, depth):
        indent = "  " * depth
        if tree_.feature[node] != _tree.TREE_UNDEFINED:
            name = feature_name[node]
            threshold = tree_.threshold[node]
            print("{}if {} <= {}:".format(indent, name, threshold))
            recurse(tree_.children_left[node], depth + 1)
            print("{}else:  # if {} > {}".format(indent, name, threshold))
            recurse(tree_.children_right[node], depth + 1)
        else:
            print("{}return {}".format(indent, tree_.value[node]))

    recurse(0, 1)

# Turning decision tree into a function

dtmToCode(dtm, X_train.columns)

# Use matplotlib to plot the tree for original dtm

from sklearn import tree
import matplotlib.pyplot as plt
plt.figure(figsize=(25,20))
_ = tree.plot_tree(dtm,
                     feature_names = X_train.columns,
                        class_names = y_train,
                        filled = True)

"""## Parameter Tuning for DTM"""

# Using the GridSearchCV module to help us find the optimal parameter values from a given set of parameters in a grid.

from sklearn.model_selection import GridSearchCV 

random.seed(8765)

# Create the parameter grid based on the results of random search 

param_grid = {
    'max_depth': [8, 10, 12],
    'max_features': [8, 9, 10],
    'min_samples_leaf': [2, 4, 6, 8, 10],
    'min_samples_split': [2, 4, 6, 8, 10, 12, 14, 16],
    'splitter': ['best', 'random']
}

# Create a based model

dtr = tree.DecisionTreeRegressor(max_depth=5)

# Instantiate the grid search model

dt_grid = GridSearchCV(estimator = dtr, param_grid = param_grid, 
                           cv = 10, n_jobs = -1, verbose = 2)

dt_grid.fit(X_train, y_train)
optimized_dtm = dt_grid.best_estimator_
dt_grid.best_params_

dtmToCode(optimized_dtm, X_train.columns)

# Use matplotlib to plot the tree for optimized dtm

from sklearn import tree
import matplotlib.pyplot as plt
plt.figure(figsize=(25,20))
_ = tree.plot_tree(optimized_dtm,
                        feature_names = X_train.columns,
                        class_names = y_train,
                        filled = True)

# Compare the results from original decision tree model to modified decision tree model

decision_tree_results = pd.DataFrame(y_train[0:20])
decision_tree_results["Original DTM"] = np.round(dtm.predict(X_train.iloc[0:20])*4)/4
decision_tree_results["Modified DTM"] = np.round(optimized_dtm.predict(X_train.iloc[0:20])*4)/4
decision_tree_results

"""#Random Forest Regression"""

# Import libraries

from sklearn.ensemble import RandomForestRegressor

# Create the random forest regressor

rfm = RandomForestRegressor(n_estimators = 100, random_state = 42)
rfm.fit(X_train, y_train)

# Use matplotlib to plot the tree

from sklearn import tree
import matplotlib.pyplot as plt
plt.figure(figsize=(25,20))
_ = tree.plot_tree(rfm.estimators_[0],
                        feature_names = X_train.columns,
                        class_names = y_train,
                        filled = True)

# Compare the results from original decision tree model to random forest model

decision_tree_results["Original RFM"] = np.round(rfm.predict(X_train.iloc[0:20])*4)/4
decision_tree_results

"""## Parameter tuning for RFM
Notes: the following code will take a little while to run.
"""

# Create the parameter grid based on the results of random search 

param_grid = {
    'bootstrap': [True],
    'max_depth': [15, 20, 25],
    'max_features': [6, 8, 10],
    'min_samples_leaf': [2],
    'min_samples_split': [10],
    'n_estimators': [100, 200, 800]
}

# Create a based model

rf = RandomForestRegressor()

# Instantiate the grid search model

rf_grid = GridSearchCV(estimator = rf, param_grid = param_grid, 
                          cv = 10, n_jobs = -1, verbose = 2)

rf_grid.fit(X_train, y_train)

optimized_rfm = rf_grid.best_estimator_

rf_grid.best_params_

"""# Rating Predictions"""

# Adding the 'Rating' column to the test set

X_test['Rating'] = y_test

# Predict the ratings for the test set using the optimized decision tree model

y_pred = optimized_dtm.predict(X_test)

# Create a dataframe to compare the actual ratings to the predicted ratings

predictions = pd.DataFrame(y_test)
predictions["Predicted"] = np.round(y_pred*4)/4
predictions

# Predict the ratings for the test set using the optimized random forest model

y_pred = optimized_rfm.predict(X_test)

# Create a dataframe to compare the actual ratings to the predicted ratings

predictions = pd.DataFrame(y_test)
predictions["Predicted"] = np.round(y_pred*4)/4
predictions

"""# Model Evaluations"""

# Using from sklearn.metrics import accuracy_score to evaluate the accuracy of the model

from sklearn.metrics import accuracy_score

# Evaluating the accuracy of the optimized decision tree model

accuracy_score(y_test, np.round(optimized_dtm.predict(X_test)))

# Evaluating the accuracy of the optimized random forest model

accuracy_score(y_test, np.round(optimized_rfm.predict(X_test)))

# Error: Classification metrics can't handle a mix of continous and multiclass targets. How to fix this? # https://stackoverflow.com/questions/62658279/classification-metrics-cant-handle-a-mix-of-continuous-and-multiclass-targets










# Import the libraries

from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score

# A function to evaluate the optimized decision tree model

def evaluate(model, test_features, test_labels):
    predictions = model.predict(test_features)
    errors = abs(predictions - test_labels)
    mape = 100 * np.mean(errors / test_labels)
    # Explain how we calcuate the mape: MAPE is calculated by taking the absolute value of the difference between the actual and predicted values, dividing it by the actual value, and then multiplying it by 100. The mean of all of these values is then taken to get the MAPE.
    accuracy = 100 - mape # The accuracy is then calculated by subtracting the MAPE from 100.
    rmse = np.sqrt(mean_squared_error(test_labels, predictions)) # Shows how far predictions fall from measured true values using Euclidean distance
    r2 = r2_score(test_labels, predictions)
    print('Model Performance\n')
    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))
    print('Accuracy = {:0.2f}%.'.format(accuracy))
    print('RMSE = {:0.2f}.'.format(rmse))
    print('R2 = {:0.2f}.'.format(r2))
    return accuracy

# Evaluate the original decision tree model

base_accuracy_original_dtm = evaluate(dtm, X_test, y_test)

# Evaluate the optimized decision tree model

base_accuracy_optimized_dtm = evaluate(optimized_dtm, X_test, y_test)

# Evaluate the original random forest model

base_accuracy_original_rfm = evaluate(rfm, X_test, y_test)

# Evaluate the optimized random forest model

base_accuracy_optimized_rfm = evaluate(optimized_rfm, X_test, y_test)








# Create a table to compare the model evaluation results by inserting the model evaluation function to thefrom original models to optimized models
# Using pandas to create a dataframe
# Should include the following columns: Model, Accuracy, RMSE, R2
# Be sure to round the values to 2 decimal places

model_evaluations = pd.DataFrame(columns = ['Model', 'Accuracy', 'RMSE', 'R2'])

model_evaluations = model_evaluations.append({'Model': 'Original DTM', 'Accuracy': base_accuracy_original_dtm, 'RMSE': np.sqrt(mean_squared_error(y_test, dtm.predict(X_test))), 'R2': r2_score(y_test, dtm.predict(X_test))}, ignore_index=True)
model_evaluations = model_evaluations.append({'Model': 'Optimized DTM', 'Accuracy': base_accuracy_optimized_dtm, 'RMSE': np.sqrt(mean_squared_error(y_test, optimized_dtm.predict(X_test))), 'R2': r2_score(y_test, optimized_dtm.predict(X_test))}, ignore_index=True)
model_evaluations = model_evaluations.append({'Model': 'Original RFM', 'Accuracy': base_accuracy_original_rfm, 'RMSE': np.sqrt(mean_squared_error(y_test, rfm.predict(X_test))), 'R2': r2_score(y_test, rfm.predict(X_test))}, ignore_index=True)
model_evaluations = model_evaluations.append({'Model': 'Optimized RFM', 'Accuracy': base_accuracy_optimized_rfm, 'RMSE': np.sqrt(mean_squared_error(y_test, optimized_rfm.predict(X_test))), 'R2': r2_score(y_test, optimized_rfm.predict(X_test))}, ignore_index=True)

model_evaluations

# The optimized decision tree model performs better than the original decision tree model.











# Using the best method available to determine top 3 variables that will have the greatest impact on chocolate bar ratings prediction for the original random forest model and the optimized random forest model
# Write a function to determine the top 3 variables that will have the greatest impact on chocolate bar ratings prediction

def top3_variables(model, X_train):
    importances = model.feature_importances_
    indices = np.argsort(importances)[::-1]
    print("Top 3 variables that will have the greatest impact on chocolate bar ratings prediction:")
    for f in range(3):
        print("%d. %s (%f)" % (f + 1, X_train.columns[indices[f]], importances[indices[f]]))

# Determine the top 3 variables that will have the greatest impact on chocolate bar ratings prediction for the original random forest model

top3_variables(rfm, X_train)

# Determine the top 3 variables that will have the greatest impact on chocolate bar ratings prediction for the optimized random forest model

top3_variables(optimized_rfm, X_train)

# Using the best method available to determine top 3 variables that will have the greatest impact on chocolate bar ratings prediction for the original decision tree model and the optimized decision tree model
# Write a function to determine the top 3 variables that will have the greatest impact on chocolate bar ratings prediction

def top3_variables(model, X_train):
    importances = model.feature_importances_
    indices = np.argsort(importances)[::-1]
    print("Top 3 variables that will have the greatest impact on chocolate bar ratings prediction:")
    for f in range(3):
        print("%d. %s (%f)" % (f + 1, X_train.columns[indices[f]], importances[indices[f]]))

# Determine the top 3 variables that will have the greatest impact on chocolate bar ratings prediction for the original decision tree model

top3_variables(dtm, X_train)

# Determine the top 3 variables that will have the greatest impact on chocolate bar ratings prediction for the optimized decision tree model

top3_variables(optimized_dtm, X_train)

# The optimized decision tree model performs better than the optimized random forest model.