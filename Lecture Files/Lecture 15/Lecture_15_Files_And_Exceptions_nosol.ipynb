{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Files and Exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCgpTncy9goQ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reading and writing files\n",
    "\n",
    "We breezed through reading files when we talked about Pandas.  Now we'll try to go back and more carefully explain what's going on, and also use this opportunity to talk about Exceptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There will come a time when you want your calculations to survive the termination of your program.  You'll want to write something to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First, we can create a CSV manually to work with.  The format isn't much more complex than comma separated values on each line, although we'd need to put strings in quotes if there were non-separator commas.  Instead, we can create a file like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FshLlRZ2-00_",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "```\n",
    "a,b,c\n",
    "d,e,f\n",
    "g,h,i\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1O-ZZRqBHgU",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This file is readable in any text editor, which is generally true of CSV files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next, if you're working in Google Colab, you need to upload this file to Google Drive before we can use it.  On the other hand, if you're working locally, it just needs to be in the same directory that you launched Jupyter notebook from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Skip this cell if not working in Google Colab\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload() # pick simple_csv.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We could import our file to a Pandas DataFrame, but we're just going to explore working with CSVs directly for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To open a file like this, we can use open() and \"with.\"  open() takes a filename string and returns a file object if it was found.  \"with\" is a handy keyword that cleans up everything associated with an object once its indented block is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def demo_read_csv(filename):\n",
    "    with open(filename, mode='r') as my_csv:\n",
    "        reader = csv.reader(my_csv)\n",
    "        for record in reader:\n",
    "            first, second, third = record\n",
    "            print(f'{first};{second};{third}')\n",
    "\n",
    "demo_read_csv('small_csv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The reader returns the file one line at a time, with each line returned as a list of strings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We could write instead of read a CSV file.  We need to change the mode from \"r\" for read to \"w\" for write, and change our reader object to a writer.  The CSV format is rather simple if you don't have to deal with values that include commas, but the CSV writer will handle these, too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# vals1, vals2 are lists of strings\n",
    "def demo_write_csv(filename, vals1, vals2):\n",
    "    with open(filename, mode = 'w') as my_csv:\n",
    "        writer = csv.writer(my_csv)\n",
    "        writer.writerow(vals1)\n",
    "        writer.writerow(vals2)\n",
    "\n",
    "vals1demo = ['peach','pear','plum']\n",
    "vals2demo = ['strawberry','orange','grape']\n",
    "\n",
    "demo_write_csv('fruits.csv',vals1demo,vals2demo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In both the read and write cases, the \"with\" keyword closes the file for us when we exit the block, freeing it up for the operating system to allow another program to use the file.  (__with__() will, in general, call the method named __exit__() for its object when the block is done.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can see the file in its directory with the !ls command.  ! alerts Google Colab that what follows is a system command of the kind you could use at the command line (Terminal in Mac), and ls is a command to list the contents of the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "CSV isn't the only viable format for writing out data.  Another popular option is JSON (JavaScript Object Notation).  JSON is popular as a platform-independent way to transfer key-value pairs; the Twitter API uses it, for example.  A JSON object is like a dictionary in that it stores property names (keys) and values associated with those keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To write a JSON object to file, you need only call json.dump on a dictionary holding the key-value pairs, also providing the file to dump the JSON into.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def demo_dump_json(filename, dict):\n",
    "    with open(filename, 'w') as myfile:\n",
    "        json.dump(dict, myfile)\n",
    "\n",
    "dict_demo = {\n",
    "    'a': 3,\n",
    "    'b': 7,\n",
    "    'c': 10\n",
    "}\n",
    "\n",
    "demo_dump_json('sample.json', dict_demo)\n",
    "\n",
    "# to target file: {\"a\": 3, \"b\": 7, \"c\": 10}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Values in JSON objects can be strings, numbers, Boolean values (but lowercase), null, arrays, or other JSON objects.  Thus they can potentially communicate richer structure than a CSV.  They're often how a variety of cloud-based services communicate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "The fancy word for committing data to a file is serialization.  Python used to use another, python-specific method of serialization called pickling -- but, it was a little too powerful, as unpacking a pickle could cause arbitrary code to execute.  Now, pickling seems to be less used in favor of platform-independent formats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "JSONs can be read into dictionaries as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def demo_read_json(filename):\n",
    "    with open(filename, 'r') as myfile:\n",
    "        my_dict = json.load(myfile)\n",
    "    return my_dict\n",
    "\n",
    "my_dict = demo_read_json('sample.json')\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The dictionary we wrote to file in the previous step can be read right back as a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tW18nit4XXBS",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise\n",
    "Try dumping a dictionary into a .json file on Google Colab, check that it's there with ls, then read it back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWb-MmNvYFvR",
    "outputId": "99b423e4-a31e-4a68-e895-66273f23413e",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mydict = {\"foo\": 2, \"bar\": 5}\n",
    "# TODO to JSON and !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aMXHCU9aYeZt",
    "outputId": "9240ab1e-f707-49a5-9b78-bc92c1fe93b9",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# TODO read back the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1APXZnXcQba",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Directly to DataFrame\n",
    "\n",
    "As we did in a previous lecture, you can load a CSV into a DataFrame without using the methods discussed in this lecture; pd.read_csv() reads directly into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "HuUnMMKZcZWD",
    "outputId": "a8a8f7ac-94a9-4948-b6df-d0cc76e20064",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"fruits.csv\", names = [\"fruit1\", \"fruit2\",\"fruit3\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pWkbZVBdi4b",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Writing a DataFrame to CSV is similarly straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFPhV-x-drJH",
    "outputId": "1270ff53-a4fc-4fbf-af28-7b20c682086e",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('fruits2.csv')\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lejZ3QboUUX4",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intro to Exceptions\n",
    "\n",
    "Input and Output (IO) is generally a place where things may not work as expected -- the looked-for file isn't there, or we didn't get permission to write. When things don't go as planned, an exception is thrown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Exceptions are objects, and there are multiple kinds depending on the error that occurred: FileNotFoundError, ZeroDivisionError, and ValueError are examples (this last occurs if you try to parse a non-integer string as an integer). If an exception occurs and it isn't \"caught,\" the program immediately terminates, reporting where the error occurred in a way you're familiar with from debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If an exception is caused by a bug, you should fix the bug instead of catching the exception. But if the exception can happen because of bad input or bad circumstances, then your program should catch it and respond gracefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The \"try\" keyword comes before a block of code that could throw an exception. If an exception is thrown, it can be \"caught\" with an \"except\" block after the try block. Execution will jump to the \"except\" when an exception in the try block occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Our JSON reader could have two obvious errors: the file doesn't exist, or the file isn't JSON. We can catch these errors in this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zix4Lc0iZGlL",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def safe_read_json(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as myfile:\n",
    "            my_dict = json.load(myfile)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found: \" + filename)\n",
    "        return None\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        print(\"JSON error in \" + filename)\n",
    "        return None\n",
    "    return my_dict\n",
    "\n",
    "safe_read_json('not_found.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8fUKYWmgr1U",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The behavior may seem very similar, but the program doesn't crash this way, and it returns a more informative error to the user.\n",
    "\n",
    "(Note that \"except\" without a specific exception following it will catch all exceptions.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Two other keywords associated with exceptions are \"else\" and \"finally.\"  \"Else\" can appear after except blocks to say what should happen if there weren't errors.  And \"finally\" can appear after all of that to give code that should happen regardless - probably some kind of cleanup.  Both are used somewhat infrequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YOMFVgklZnBe",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def safe_read_json_last_call(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as myfile:\n",
    "            my_dict = json.load(myfile)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found: \" + filename)\n",
    "        return None\n",
    "    else:\n",
    "        print(\"No errors!\")\n",
    "    finally:\n",
    "        print(\"End of demo!\")\n",
    "        \n",
    "safe_read_json_last_call('sample.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4i2tHgMHZwTr",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You should never use exceptions for the normal, expected running of your program - they're for use in surprising, unexpected situations.  The way they jump around in the code is undesirable, but it's better than the program crashing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-h5tgMcZ0RX",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise\n",
    "\n",
    "Modify the CSV reading function demo_read_csv so that it catches a FileNotFoundError and a ValueError (for wrong number of items in a line). Print an error message in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "miyBuFY3aRk0",
    "outputId": "cc1c44bb-3bd6-4743-e8b0-6ea8319b613c",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def demo_read_csv(filename):\n",
    "    with open(filename, mode='r') as my_csv:\n",
    "        reader = csv.reader(my_csv)\n",
    "        for record in reader:\n",
    "            first, second, third = record\n",
    "            print(f'{first};{second};{third}')\n",
    "\n",
    "demo_read_csv(\"fruits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "name": "Lecture13FilesAndExceptions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0a5 (v3.11.0a5:c4e4b91557, Feb  3 2022, 14:54:01) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "rise": {
   "scroll": true
  },
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
