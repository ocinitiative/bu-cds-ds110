{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9bvqQsycmln"
   },
   "source": [
    "# HW4 - 60 points possible\n",
    "\n",
    "Also needs the data file books.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGXZGIaswg9m"
   },
   "source": [
    "# Problem 1:  Sets and Dictionaries (23 pts:  7,8,8)\n",
    "\n",
    "a, 7 pts) Write a function total_value() that takes a list and a dictionary as arguments, and returns the total value of all the items in the list given their values in the dictionary.  If an item isn't in the dictionary, it is worth 0. For example, if ['Copper','Gold','Smithy'] was passed along with a dictionary that gave values of 1 for Copper and 3 for Gold, with Smithy not in the dictionary, then the function would return 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48dT0lZyxW9u"
   },
   "outputs": [],
   "source": [
    "# TODO total_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0e37jL2x3MR"
   },
   "outputs": [],
   "source": [
    "coins = {'Copper':1,'Silver':2,'Gold': 3}\n",
    "total_value(['Copper','Gold','Smithy'], coins) # expect 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YR_EZvezzSu8"
   },
   "source": [
    "b, 8pts) Write a function tuples_to_dict() that, given a list of (string, number) tuples, returns a dictionary where the keys are the strings from the list and their values are the numbers that were associated with those strings.  If a key appears twice or more in the list, then the associated values should be summed.  For example, tuples_to_dict([('words', 5),('and',4),('words',3),('and',2]) would produce the dictionary {'and': 6, 'words': 8}.  You don't need to clean or transform the strings in any way (for example, by making them all lowercase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9i5o1mfYSZM_"
   },
   "outputs": [],
   "source": [
    "# TODO tuples_to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uOpEdnfDS41g"
   },
   "outputs": [],
   "source": [
    "tuples_to_dict([('words',5),('and',4),('words', 3),('and',2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JSXyuKoXfkL"
   },
   "source": [
    "c, 8pts) Write a function merge_counts() that takes two dictionaries as arguments and returns a single dictionary where the value for each key is the sum of the values for that key across the two dictionaries.  (If a key is just in one dictionary, its value is the value in the merged dictionary.)  Thus merge_counts({'words': 2, 'and':1},{'words':1,'and':1,'more':1}) would result in the dictionary {'and':2,'more':1',words':3}.  Your code can modify either of the passed in dictionaries if you would find it convenient, as long as your output is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fixc7_k0S-Mo"
   },
   "outputs": [],
   "source": [
    "# TODO merge_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7z43MvqeZvdo"
   },
   "outputs": [],
   "source": [
    "merge_counts({'words': 2, 'and':1},{'words':1,'and':1,'more':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeMnlatvbY8o"
   },
   "source": [
    "# Problem 2:  Books (37 points:  2,4,5,10,8,8)\n",
    "\n",
    "Download the books.csv file from the same place you downloaded this assignment; it's a dataset originally posted on the competition site Kaggle (but cleaned up slightly) and collected from the website Goodreads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BhrSSoZ6Zzjw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.colab import files\n",
    "import io\n",
    "\n",
    "uploaded = files.upload() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BVltV-wsdV18"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(io.BytesIO(uploaded['books.csv']), index_col = 'title')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qHo-6F8ixEz"
   },
   "source": [
    "a, 2 pts)  Run describe() on this data to get a quick idea as to how everything varies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAT6iFAciR17"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lbc8-8vEkGAV"
   },
   "source": [
    "b, 4pts) Find the book with the greatest number of pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jW1RBwU5i9ji"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAyRE-uHz6hw"
   },
   "source": [
    "c,5pts) Find all the books with an average rating of at least 4.98."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ULqDiMhF0Btb"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNE0fc8Ezvpb"
   },
   "source": [
    "d, 10pts)  Take a look at the ratings_count column of your results:  these books all got high ratings partly because very few people reviewed them.\n",
    "\n",
    "Some ratings systems, like the one at boardgamegeek.com, try to take small sample size into account by giving every item some number of average-valued \"ghost ratings\" that drag the rating toward the middle of the scoring system until enough ratings are accumulated to overcome the effect.\n",
    "\n",
    "Write a function adjusted_rating() that takes as two arguments the string title of a book and the dataframe, and returns what the average rating of the book would be if it had 300 more ratings of 3.  The formula is $\\frac{averagerating \\times ratingscount + 3 \\times 300}{ratingscount+300}$.  You can assume the string input is a book title that appears in the index exactly once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z5FD4_SSkZJ4"
   },
   "outputs": [],
   "source": [
    "# TODO adjusted_rating()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m1aBk4sd3oRq"
   },
   "outputs": [],
   "source": [
    "adjusted_rating('Stranger in a Strange Land', df) # roughly 3.92, very close to unadjusted score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYVWhICC3qxD"
   },
   "outputs": [],
   "source": [
    "adjusted_rating('Taxation of Mineral Rents', df) # had 5.0 with only one rating; adjusted, it's rated about 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25MeGfBV7jAu"
   },
   "source": [
    "e, 8 pts) Is there any consistent relationship between book length and rating?  Let's visualize it - plot these using matplotlib in a scatter plot with number of pages on the x axis and average rating (unadjusted) on the y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHwBuiap73Ko"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcPOlSrw80SY"
   },
   "source": [
    "f, 8 pts) Make that same plot, but this time, exclude books over 1000 pages and books that have fewer than 10 ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nEF1sS-D31K4"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "YourName_DS110_F22_HW4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
