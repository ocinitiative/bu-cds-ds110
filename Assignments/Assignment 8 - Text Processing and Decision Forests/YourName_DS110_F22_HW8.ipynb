{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Sjqb47ZM6FM"
      },
      "source": [
        "# HW8 (60 points possible)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f0bPxFgDLZk"
      },
      "source": [
        "This homework also needs winequality-red.csv, which you can find at the same place you found this homework or at the UCI Machine Learning repository (https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS8ThAcgM-4K"
      },
      "source": [
        "# Problem 1:  Scraping Rotten Tomatoes (24 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qrRi6ADOWOE"
      },
      "source": [
        "Rotten Tomatoes is a website that aggregates movie critic reviews.  Use the requests module to get the Rotten Tomatoes review site for *Star Wars:  A New Hope*, at URL https://www.rottentomatoes.com/m/star_wars_a_new_hope/reviews?intcmp=rt-scorecard_tomatometer-reviews .  Then use Beautiful Soup to extract all div tags with a class of 'the_review'.  Use Beautiful Soup's get_text() method to remove the tags from these text snippets, and finally, use the TextBlob class to print a Sentiment for each sentence, separated from the sentence itself by '::'.\n",
        "\n",
        "For example, the expected output for one review would be:  \"Star Wars is the best science fiction film that’s come down the pike to date.::Sentiment(polarity=0.4222222222222222, subjectivity=0.29444444444444445)\n",
        "And every good thing you’ve heard about it is true.::Sentiment(polarity=0.5249999999999999, subjectivity=0.625)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BG4I5PtzI2J-"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLVrWUgi8YSZ"
      },
      "source": [
        "# Problem 2:  Random Forests (27 points:  3,6,6,12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I4nLXBx_vdf"
      },
      "source": [
        "For this exercise, we'll try using random forests to predict wine quality.  The dataset is from the UCI Machine Learning repository, and rates wines on a scale from 1 to 10.  To turn this into a binary classification problem, we are just interested in identifying wines with a quality score of 7 or more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt3UE8Lv_wQa"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload() # Upload winequality-red.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEzMl7DZAMs0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('winequality-red.csv', sep = ';')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLFwCzE2A4vV"
      },
      "source": [
        "To help you, below we've turned the final column into a *target* vector and created a DataFrame *features* that consists of all the other columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwG-XRYrA5d0"
      },
      "outputs": [],
      "source": [
        "target = df['quality'] >= 7\n",
        "features = df.iloc[:,0:11]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll9M3w_ZEr4s"
      },
      "source": [
        "a, 3 pts) Separate the features and target vector into training and testing data with scikit-learn's *train_test_split()* function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTM05b_MB1yV"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfzElL_nE8rx"
      },
      "source": [
        "b, 6 pts) Use the RandomForestClassifier of sklearn.ensemble to create a random forest with 200 trees.  Train on the training data with *fit()*, and test on the test data with *score()*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBTAAwl2CHd-"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvYZmKjeFfbl"
      },
      "source": [
        "c, 6 pts) Consult the classifier's feature_importances_ attribute.  What is the most important feature that the classifier is using to classify the wines?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkejNjt5FZOK"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9B-xB_2GU4P"
      },
      "source": [
        "**TODO most important feature**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DODp0APRIMdp"
      },
      "source": [
        "d, 12 points) Run an experiment in which you find the average test score over 100 trials for a scikit-learn decision tree classifier trained on the wine quality data.  Compare its performance to the average score over 100 trials of a random forest with *just one tree*.  What's one difference between these two classifiers that can explain the slight difference in average scores?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRZx8IiUG3cl"
      },
      "outputs": [],
      "source": [
        "# TODO Decision Tree part of the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peZurCoeIuTp"
      },
      "outputs": [],
      "source": [
        "# TODO Random Forest with one tree part of the experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRcL89G7Q4qu"
      },
      "source": [
        "**TODO explain the difference**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ8CVUafSR4k"
      },
      "source": [
        "# Problem 3:  Text Processing (9 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGhELYgiV9dw"
      },
      "source": [
        "Write a function just_verbs() that takes a string as an argument, and returns a list of the verbs in the sentence.  (Note that the tags returned in the .tags attribute of a TextBlob start with 'VB' for verbs.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FP0WV2SdWe4u"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVImvzOQXA1o"
      },
      "outputs": [],
      "source": [
        "# TODO just_verbs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDU0IO7AXXId"
      },
      "outputs": [],
      "source": [
        "# Test - should produce ['jumped', 'sang']\n",
        "just_verbs('I jumped and sang')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.0a5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
