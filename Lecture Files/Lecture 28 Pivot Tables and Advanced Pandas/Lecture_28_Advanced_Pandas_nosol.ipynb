{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advanced Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oiC6BgUMCUDU",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pivot tables\n",
    "\n",
    "Pivot tables are a way of organizing data so that the values of particular combinations of features are highlighted.  For example, if you're looking at resale value of used cars, and have a long list of used cars before you, a pivot table could help you see the average resale value of a red 2013 Honda Fit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "How a pivot table works is best illustrated with an example (modified from the API reference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOBdUqI2CPkN",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"Creature\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
    "                         \"bar\", \"bar\", \"bar\", \"bar\"],\n",
    "                   \"Type\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
    "                          \"one\", \"one\", \"two\", \"two\"],\n",
    "                   \"Size\": [\"small\", \"large\", \"large\", \"small\", \"small\",\n",
    "                         \"large\", \"small\", \"small\", \"large\"],\n",
    "                   \"Number1\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
    "                   \"Number2\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZqjL5smJX-c",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are repeated values and a missing combination of features (no \"foo two large\"), but these facts are hard to determine by scanning the data.  Instead, we can create a table that summarizes the average values for each combination of Creature, Type, and Size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iy9Ntei0J4BX",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "table = pd.pivot_table(df, values='Number1', index=['Creature', 'Type'], columns=['Size'], aggfunc=np.mean)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i75pK_LdKS_x",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The table shows the average value for each combination of three attributes (Foobar, Type, and Size), putting NaN where no such combination was found.  Foobar and Type were passed as indices, so their combinations appear on the left.  Size was passed as a column.  And numpy.mean was given as the way to combine multiple values for the same feature combinations; we could have added instead if we were looking at total sales or something similar.  (Notice also that the Number2 values were dropped, as all the values are now from column Number1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHV13zjALimN",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here's a slightly less abstract example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJBVJE4OLl18",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Model\": [\"Fit\", \"Corolla\", \"Civic\", \"Fit\", \"Civic\",\n",
    "                             \"Corolla\",\"Civic\", \"Fit\", \"Corolla\",\n",
    "                             \"Fit\", \"Civic\"],\n",
    "                   \"Color\": [\"red\", \"blue\", \"red\", \"silver\", \"red\",\n",
    "                             \"blue\", \"silver\", \"red\", \"blue\",\n",
    "                             \"silver\", \"silver\"],\n",
    "                   \"Year\": [2009, 2010, 2009, 2011, 2012,\n",
    "                          2012, 2009, 2010, 2011, 2010, 2012],\n",
    "                   \"Price\": [3300, 3600, 3000, 4000, 4200,\n",
    "                             4300, 2000, 3000, 3600, 3200,4500]})\n",
    "\n",
    "table = pd.pivot_table(df, values='Price', index=['Model', 'Color'], columns=['Year'], aggfunc=np.mean)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtUWL_tzS7xe",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "The same grouping that we see in the rows, we could perform in the columns.  Each entry still represents the intersection of 3 attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EF-z7hv5THs7",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "table = pd.pivot_table(df, values='Price', index=['Color'], columns=['Model','Year'], aggfunc=np.mean)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_3TVLVgN5kr",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "With so many missing values, we could decide to not care about the year.  This will group entries with different years together, as long as they agree on Model and Color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ey1erB2VN-39",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "table = pd.pivot_table(df, values='Price', index=['Model'], columns=['Color'], aggfunc=np.mean)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkcIibwcOQFm",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now all the different years are being averaged together for the same color and model of car.\n",
    "\n",
    "The fill_value parameter replaces the NaN's with some other value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lP-EO54oO2_Q",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "table = pd.pivot_table(df, values='Price', index=['Model'], columns=['Color'], aggfunc=np.mean, fill_value=0)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7DubvaTO-Fa",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It's also possible to include multiple values and multiple statistics  in the same table, using different columns.  aggfunc can take a dictionary from value name to function instead of a single function as its argument.  The dictionary values can even be lists of functions instead of single functions. See the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YY2XhBH9PJNl",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "table = pd.pivot_table(df, values=['Year','Price'], index=['Model', 'Color'],\n",
    "                       aggfunc={'Year': [min, max], 'Price': np.mean})\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuUSAbNeibOI",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The pivot table is for seeing patterns in data, so you should use whatever layout best illustrates answers your questions.  For example, we could ask, does color change how a car's value changes over time?  As we're watching price change with the year over time, it makes sense to make the color a row, and the year a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HdV5-rp5j9_d",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "table = pd.pivot_table(df, values='Price', index=['Color'], columns=['Year'], aggfunc=np.mean)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the table itself isn't easy to read, it's straightforward to pass the pivot table to one of several kinds of plot with the plot() method of the dataframe.  See the pandas.DataFrame.plot() documentation for more types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WCUHxVOTwTU",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise\n",
    "\n",
    "Try predicting what the table will look like when the following pivot_table methods are called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1syD-3z6PKxo",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({\"Student\": [\"Alice\", \"Bob\", \"Chu\", \"Dedue\", \"Egla\", \"Fatima\",\"Grund\"],\n",
    "                   \"GPA\": [4.0, 3.5, 3.8, 2.8, 3.9, 3.7, 4.0],\n",
    "                   \"GradYear\": [2022, 2023, 2022, 2024, 2022, 2024, 2023],\n",
    "                   \"Major\": [\"EE\",\"CS\",\"EE\",\"CS\",\"EE\",\"CS\",\"EE\"],\n",
    "                   \"Took110\": [False, True, False, True, False, False, False]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGwuJcS7T-Zu",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "table = pd.pivot_table(df, values='GPA', index=['Major'], columns=['GradYear'], aggfunc=np.mean)\n",
    "table\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0UINK9C9NQDE",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "table = pd.pivot_table(df, values='GPA', index=['Major','GradYear'], aggfunc={'GPA': [np.mean, max]})\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fiZ0auwUOVxu",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "table = pd.pivot_table(df, values='GPA', index=['Major'], columns=['GradYear','Took110'], aggfunc=np.mean)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZoRoW5Fkh5U",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Groupby\n",
    "\n",
    "A related method is groupby(), which groups the entries by a particular value they have in common (such as same model of car).  This allows for a quick mean() of the other features of those individuals.  It's like a pivot table, but doesn't necessarily need multiple different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2kC8N9-Ik6wK",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby([\"Major\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORZD51KgO7h3",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It may make sense to run the groupby only on particular columns, which should include the one you want to run groupby on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0nZbhmKOOM1_",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df[[\"GPA\", \"Major\"]].groupby([\"Major\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMtn2U6zViFb",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can also groupby multiple criteria, so it finds the average (or other statistic) for each combination.  Groupby's result then starts to look like a pivot table (it's actually a MultiIndex)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZX9mxFoIVvGt",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby([\"Major\",\"GradYear\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYg-usBlWoi5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise\n",
    "\n",
    "Use groupby on the cars dataframe to find the average price for each model.  Try to only include the price information, and not the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLNsBKnFW843",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "cars = pd.DataFrame({\"Model\": [\"Fit\", \"Corolla\", \"Civic\", \"Fit\", \"Civic\",\n",
    "                             \"Corolla\",\"Civic\", \"Fit\", \"Corolla\"],\n",
    "                   \"Color\": [\"red\", \"blue\", \"red\", \"silver\", \"red\",\n",
    "                             \"blue\", \"silver\", \"red\", \"blue\"],\n",
    "                   \"Year\": [2009, 2010, 2009, 2011, 2013,\n",
    "                          2013, 2009, 2010, 2011],\n",
    "                   \"Price\": [3300, 3600, 3000, 4000, 4000,\n",
    "                             4000, 2000, 3000, 3000]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0_XZ_wuUXGZH",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EINHMi9WRnIP",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Merging tables\n",
    "\n",
    "You can *join* tables on the basis of shared key values.  You need to pass the name of each table's column to join on, as left_on and right_on.  The join will create a table with rows that combine rows from each table, using the column to join on as the identity that links both tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M06kX68bTWGl",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "grade_df = pd.DataFrame({'Name': ['Alice', 'Bob', 'Chu', 'Daisy'],\n",
    "                    'GPA': [4.0, 3.5, 3.9, 3.1]})\n",
    "\n",
    "major_df = pd.DataFrame({'Name': ['Alice', 'Bob', 'Chu', 'Daisy'],\n",
    "                        'Major': ['EE', 'CS', 'EE', 'CS']})\n",
    "\n",
    "merged_df = grade_df.merge(major_df, left_on = 'Name', right_on = 'Name')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2sqiZG6Wt5Z",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, it's possible that either one of the tables is missing some keys that the other has.  The default behavior is to ignore any rows that are missing from the other table, in both tables.  This is called an 'inner join.'  But, if you want some other kind of join, you can specify this in the \"how\" parameter.  An \"outer\" join creates rows for records that have either key, and a \"left\" or \"right\" join creates rows according to just the left table's or right table's keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0cvMsFrXbIS",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# These two lists now differ in their D person\n",
    "\n",
    "grade_df = pd.DataFrame({'Name': ['Alice', 'Bob', 'Chu', 'Dominique'],\n",
    "                    'GPA': [4.0, 3.5, 3.9,3.1]})\n",
    "\n",
    "major_df = pd.DataFrame({'Name': ['Alice', 'Bob', 'Chu', 'Daisy'],\n",
    "                        'Major': ['EE', 'CS', 'EE', 'CS']})\n",
    "\n",
    "outer_merge = grade_df.merge(major_df, how=\"outer\", left_on='Name', right_on='Name')\n",
    "outer_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oy69AKoFX_yD",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "inner_merge = grade_df.merge(major_df, how=\"inner\",left_on='Name',right_on='Name') # also the default\n",
    "inner_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7std1gb1YM9Z",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "left_merge = grade_df.merge(major_df, how=\"left\", left_on='Name',right_on='Name')\n",
    "left_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwC0D2XOPHK4",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise\n",
    "\n",
    "If the two lists of keys to merge on are ['X', 'Y', 'Z'] and ['W', 'X', 'Y'], predict which keys are kept in an inner merge, outer merge, and right merge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttj3QqMPYL-2",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Missing values\n",
    "\n",
    "The values NaN (not a number), None, and pd.NA are all used for missing values in Pandas.  As a first pass to dealing with missing values, isna() returns True in exactly those places in the data where values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JqKhMX6mftUB",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "outer_merge.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zbHJ8n1f2JP",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One reasonable response is to drop the missing value rows altogether.  The dropna() method does this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDUYjE17f_wH",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "inner_merge = outer_merge.dropna()\n",
    "inner_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5erN0AKgYwB",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Another reasonable response would be to fill the missing data with default values.  The fillna() method does this.  For individual entries, you could set them by hand, but fillna() will work across the DataFrame or Series.  (Recall that columns are Series, and you can access them with dot operators.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-rFoOCv6g7dO",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "outer_merge.GPA = outer_merge.GPA.fillna(0)\n",
    "outer_merge.Major = outer_merge.Major.fillna(\"Undeclared\")\n",
    "outer_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQ84Uah0g6b8",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are further ways to interpolate the data for missing values(such as passing a mean() to fillna), but dropping the values or \n",
    "inserting default values will be what you want in most cases.  See the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html) for more on how to interpolate values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKzzHhOJRT2h",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assorted Other Pandas Functionality\n",
    "\n",
    "The sort_values() function will sort by a column's values -- good for seeing some of the most extreme values.  The \"by\" argument gives the column to sort by.  Sorting in ascending order is the default.  If the result is big, you can run this through a head() command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjUksrlARklu",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Name': ['Alice', 'Bob', 'Chu', 'Dominique'],\n",
    "                         'GPA': [4.0, 3.5, 3.9,3.1],\n",
    "                         'Major': ['EE', 'CS', 'EE', 'CS']})\n",
    "\n",
    "df[[\"Name\",\"GPA\"]].sort_values(by=\"GPA\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0d2OyVDSx1T",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can insert a new column in the table that is computed from another column.  Keeping computations around in the table can help troubleshooting later, or reveal patterns you didn't expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VFOu_aeSwWM",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Above 3.5\"] = df[\"GPA\"] >= 3.5\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hUXbtyPTZC9",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If it's easier to read the table with the new column next to another specific column, you can use insert() to set the column index.  Its arguments are the column index, column title, and new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sk0CYDa_R570",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df.insert(2, \"Above 3.8\", df[\"GPA\"] >= 3.8)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "name": "Lecture31AdvancedPandas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
