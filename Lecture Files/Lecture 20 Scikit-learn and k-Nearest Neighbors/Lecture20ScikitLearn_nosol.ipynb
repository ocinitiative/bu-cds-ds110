{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Supervised Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iQczNuFDlAt",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Supervised machine learning generally accomplishes one of two kinds of tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "* Classification.  Once fully trained, the learning algorithm can identify categories of things.\n",
    "\n",
    "For images, this could be faces versus not faces, or what kind of animal, or what letter was handwritten.  For audio, it could classify the word that was spoken.  For emails, it could decide what is spam.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "* Regression.  Regression attempts to fit a function (typically with numerical output) to some data.  Prediction of prices of apartments given their attributes, or predicting who has the advantage in a game given the pieces - these are regression problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Both of these fall under supervised machine learning because of the way the learning works:  the learner has many \"labeled examples\" that are inputs labeled with the correct output.  The learner has \"the answers\" for all the training data, and it just needs to find a function that interpolates and extrapolates reasonably from there.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Depending on the learning algorithm and how much data there is to process, *training*, or building the function that classifies or interpolates, could take a long time.  But here we're going to present an algorithm that takes basically no time to train:  k-nearest neighbors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sb6xLaXGmvF",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sample problem:  digits\n",
    "\n",
    "Our dataset that we will try to learn from will be a relatively simple one:  the digits library of scikit-learn.  It's grayscale instead of color, and relatively low resolution, and there's nothing in the image besides the digit to cause confusion, so this would be considered a relatively easy dataset to learn from.\n",
    "\n",
    "The data consists of 8x8=64 brightness values, labeled with the correct digit.  The task is classification:  presented with a new digit, a trained learner should be able to produce a correct classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bpCmhSjkHiQP",
    "outputId": "96b18659-3820-4f62-f946-d7908bd1e84b",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "digits = load_digits()\n",
    "print(digits.data.shape) # Examples x 64 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "9uxCF4haIX4X",
    "outputId": "7838648e-aef6-45e3-9f4e-9c1a39cfe527",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.gray() \n",
    "plt.matshow(digits.images[0]) # Notice images[0] is 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flIZaWfVGO8X",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# k-nearest neighbors\n",
    "\n",
    "The k-nearest neighbors strategy is most easily pictured in two dimensions, even though we're dealing with 64 dimensions here.  Images representing the same digit should tend to cluster near each other with similar values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "To find the correct classification of a point, we consult its neighbors - the *k* (let's say 3) closest examples that it does have a label for.  If they all agree on their own classification, then this is a very good guess for the new point.  But if they disagree, then the must vote, and majority rule determines the label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "(What does closest mean?  We typically use Euclidean distance between the data vectors. Letting $\\Delta x_i$ be a difference in a particular vector element $i$, such as the difference at one pixel, the distance is $\\sqrt{\\Delta x_1^2 + \\Delta x_2^2 + \\ldots + \\Delta x_n^2}$.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Most learning algorithms in scikit-learn spend a while adapting to the data, but k-nearest neighbors requires very little setup.  As a speed adaptation, the algorithm may create some additional structures that make lookup of the three closest fast (using hash tables in creative ways).  But that's about it - from beginning to end, the prediction for a point is the majority vote of the k closest neighbors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Let's see how to train on all the digits data available for scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9rSBiqY8DffH",
    "outputId": "b6458cb0-f754-4b4f-ce27-917251e05942",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# \"Fit\" is the name of all training methods in scikit-learn;\n",
    "# neighbors doesn't fit so much as store for efficient retrieval\n",
    "nbrs = KNeighborsClassifier(n_neighbors=3).fit(digits.data, digits.target)\n",
    "\n",
    "nbrs.score(digits.data, digits.target) # Find accuracy on the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cB2W_q-WTS1u",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The train/test split and overfitting\n",
    "\n",
    "The previous results of 99% accuracy were a little too good to be true.  We used k-nearest neighbors where one \"neighbor\" was always the original, labeled point itself.  (Reducing k to 1 thus would do what?) It seems like cheating to be given the answers ahead of time in this way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In general, most classifiers have this issue - you shouldn't evaluate solely on your training data, or the results won't give a sense of how well you do on genuinely new data points.  In fact, many algorithms run the risk of getting too cozy with the training data and *overfitting* to its idiosyncracies, learning rules that only happen to be true of the training data in particular. You can't tell whether that has happened if you just evaluate on the training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So, at the very least, you must *split the data into training and testing data*.  It's best to do this blindly and randomly, because the distributions of training and testing data should match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "You're allowed to use a much larger portion of training data for training - somewhere between 5% and 20% of your data should be reserved for testing.\n",
    "\n",
    "Scikit-learn's train_test_split() function performs exactly this task of separating out randomly selected examples for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSB4k3O7UqyT",
    "outputId": "c884fe1f-5a6c-4809-ceff-f02898364f64",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test, label_train, label_test = train_test_split(digits.data, digits.target, test_size=0.2)\n",
    "nbrs = KNeighborsClassifier(n_neighbors=3).fit(data_train, label_train)\n",
    "\n",
    "nbrs.score(data_test,label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rpJgOhJWYwh",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "It turns out, on this dataset, K-nearest neighbors will still do great - still nearly 99% accuracy when the training data is separated from the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "nbrs.predict(data_test[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def reshape_and_show(num, data_test):\n",
    "    image = data_test[num].reshape(8,8)\n",
    "    plt.matshow(image)\n",
    "\n",
    "reshape_and_show(0,data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "reshape_and_show(1,data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "reshape_and_show(2,data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zO7ngZRmXV4F",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But there must be something k-nearest neighbors is bad at, or people wouldn't get so excited about neural networks.  Let's try a harder dataset -- a faces dataset.\n",
    "\n",
    "The LFW (Labeled Faces in the Wild) dataset is another in scikit-learn.  The faces are labeled with who they are.  We can ask for just the faces supported by at least 100 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "bvLwkJMnXxKE",
    "outputId": "c6d9e41c-d52f-4378-88e3-ccc429e94a84",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "\n",
    "faces = fetch_lfw_people(min_faces_per_person = 100)\n",
    "\n",
    "plt.imshow(faces.images[5], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vSMCSybiYzBd",
    "outputId": "14d3a03f-6d70-465e-f1b1-e182e2b1861a",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data_train, data_test, label_train, label_test = train_test_split(faces.data, faces.target, test_size=0.2)\n",
    "nbrs = KNeighborsClassifier(n_neighbors=3).fit(data_train, label_train)\n",
    " \n",
    "nbrs.score(data_test,label_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbQuYGjfZShI",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Better than chance, as there are 5 people in the data and chance would be 0.2, but clearly there's room for improvement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rp4TLibpZtCU",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Validation data and strategies\n",
    "\n",
    "Can we go back and change our choice of k?  You shouldn't, because once you've looked at the test data, any changes you make could start creating improvement that doesn't carry over to the real world.  Your choices from here on out could cause overfitting to the test data.\n",
    "\n",
    "It's probably not as bad as overfitting to the training data, because the overfitting is indirect - you're changing parameters rather than telling the answers directly.  Still, expect a performance drop on moving to the \"real world\" if you went back and forth trying to get the best test score possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A way to avoid this problem is to split the training data yet again, splitting off a portion of the training data to be \"validation data.\"  Now you can go back and forth trying to improve your performance without worrying that test set knowledge is leaking into your decisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A still more clever idea is to rotate which fraction of your training data is the validation set.  So you train on the first 80% then test on 20%, then train on the first 60% and last 20% while training on that missing 20%, and so on 5 times (for example).  Ideally, this is still separate from the test data, which is reserved for final testing.  This is called \"cross-validation.\"\n",
    "\n",
    "An extreme version in which just 1 example is left out every time is called \"leave-one-out-cross-validation,\" or LOOCV for short.  This ideally gives a more accurate view of the algorithm under different circumstances, and is less dependent on which data is validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scikit-learn similarly has a function for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S61Bc8kSbxZX",
    "outputId": "9f6f4cc9-b910-4f5f-b592-4f6427898b87",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(nbrs, data_train, label_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBWdV8_wbw4g",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some part of machine learning is just trying different parameters to see what works best - although as we'll discover, we don't expect k-nearest neighbors to work that well regardless of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7q9tsz85cki9",
    "outputId": "2edb55bf-5d2e-48a0-e49a-5886b6bc27b8",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i in range(1,10):\n",
    "  nbrs = KNeighborsClassifier(n_neighbors=i)\n",
    "  print(np.mean(cross_val_score(nbrs, data_train, label_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VOsPmYDc_Bn",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Back to k-NN\n",
    "\n",
    "k-nearest neighbors can be adapted to other kinds of datasets besides numerical.  Boolean variables can be turned into 0 or 1.  Categorical variables (like strings) can be turned into \"one-hot\" encodings, where each possible category gets a boolean variable.\n",
    "\n",
    "Numbers could be standardized by dividing by their maximum, or by their standard deviation; this keeps numbers' inherent scales from biasing the distance calculations.  (Converting a scale from miles to inches shouldn't make the feature seem suddenly more important, just because the numbers are bigger.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But, kNN isn't that powerful for high-dimensional machine learning problems.  With many dimensions, random points aren't all that close or similar, so the reasoning for the method breaks down.  Datasets with very high kNN performance are the exception.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Still, k-nearest neighbors is a bona fide machine learning method, and can serve as a nice benchmark to see how well other methods are doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fkvCyueeBfJ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise\n",
    "\n",
    "Try \"training\" a knn classifier on the Iris dataset (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html) and see your cross-validation performance with cross_val_score()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzeI6-7DeOP1",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "iris = load_iris()\n",
    "# Just two lines missing or so!  Create the classifier and find the cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "name": "Lecture18ScikitLearn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
